{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingFile = \"../data/FeaturesAsMatrixv1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import merge\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5_mols'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrainingData.columns[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrainingData = pd.read_csv(trainingFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetCols = [\"%d_target\"%i for i in range(0,50)]\n",
    "molregnoCols =  [\"%d_mols\"%i for i in range(0,50)]\n",
    "latentFeatCols = [\"%d_latfeatures\"%i for i in range(0,292)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetArr = np.asarray(dfTrainingData.as_matrix(columns=targetCols))\n",
    "molregNoArr = np.asarray(dfTrainingData.as_matrix(columns=molregnoCols))\n",
    "latfeatureArr = np.asarray(dfTrainingData.as_matrix(columns=latentFeatCols))\n",
    "\n",
    "\n",
    "#targetArr = (dfTrainingData[targetCols])\n",
    "#molregNoArr = (dfTrainingData[molregnoCols])\n",
    "#latfeatureArr = (dfTrainingData[latentFeatCols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Build Sequential network\n",
    "\n",
    "targetInput = Input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "targetInput = Input(shape=(50,))\n",
    "x1 = Dense(100, activation='linear')(targetInput)\n",
    "x1 = Dense(150, activation='linear')(x1)\n",
    "\n",
    "\n",
    "molregnoInput = Input(shape=(50,))\n",
    "x2 = Dense(100, activation='linear')(molregnoInput)\n",
    "x2 = Dense(150, activation='linear')(x2)\n",
    "\n",
    "mergedLayer = merge([x1,x2],concat_axis=1,mode=\"concat\")\n",
    "####merge function is depreceted - change it next revision\n",
    "\n",
    "x = Dense(200, activation='linear')(mergedLayer)\n",
    "x = Dense(250, activation='linear')(x)\n",
    "outputLayer = Dense(292, activation='linear')(x)\n",
    "\n",
    "model = Model([targetInput,molregnoInput],outputLayer)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35955/35955 [==============================] - 15s 425us/step - loss: 0.0434\n",
      "Epoch 2/100\n",
      "35955/35955 [==============================] - 11s 311us/step - loss: 0.0139\n",
      "Epoch 3/100\n",
      "35955/35955 [==============================] - 11s 305us/step - loss: 0.0119\n",
      "Epoch 4/100\n",
      "35955/35955 [==============================] - 11s 313us/step - loss: 0.0110\n",
      "Epoch 5/100\n",
      "35955/35955 [==============================] - 11s 317us/step - loss: 0.0104\n",
      "Epoch 6/100\n",
      "35955/35955 [==============================] - 12s 322us/step - loss: 0.0100\n",
      "Epoch 7/100\n",
      "35955/35955 [==============================] - 11s 318us/step - loss: 0.0097\n",
      "Epoch 8/100\n",
      "35955/35955 [==============================] - 11s 318us/step - loss: 0.0094\n",
      "Epoch 9/100\n",
      "35955/35955 [==============================] - 12s 320us/step - loss: 0.0092\n",
      "Epoch 10/100\n",
      "35955/35955 [==============================] - 12s 323us/step - loss: 0.0090\n",
      "Epoch 11/100\n",
      "35955/35955 [==============================] - 12s 322us/step - loss: 0.0089\n",
      "Epoch 12/100\n",
      "35955/35955 [==============================] - 12s 323us/step - loss: 0.0088\n",
      "Epoch 13/100\n",
      "35955/35955 [==============================] - 12s 325us/step - loss: 0.0087\n",
      "Epoch 14/100\n",
      "35955/35955 [==============================] - 12s 321us/step - loss: 0.0085\n",
      "Epoch 15/100\n",
      "35955/35955 [==============================] - 12s 324us/step - loss: 0.0085\n",
      "Epoch 16/100\n",
      "35955/35955 [==============================] - 12s 323us/step - loss: 0.0084\n",
      "Epoch 17/100\n",
      "35955/35955 [==============================] - 12s 321us/step - loss: 0.0083\n",
      "Epoch 18/100\n",
      "35955/35955 [==============================] - 12s 326us/step - loss: 0.0082\n",
      "Epoch 19/100\n",
      "35955/35955 [==============================] - 12s 325us/step - loss: 0.0082\n",
      "Epoch 20/100\n",
      "35955/35955 [==============================] - 12s 324us/step - loss: 0.0081\n",
      "Epoch 21/100\n",
      "35955/35955 [==============================] - 12s 326us/step - loss: 0.0081\n",
      "Epoch 22/100\n",
      "35955/35955 [==============================] - 12s 325us/step - loss: 0.0080\n",
      "Epoch 23/100\n",
      "35955/35955 [==============================] - 12s 328us/step - loss: 0.0080\n",
      "Epoch 24/100\n",
      "35955/35955 [==============================] - 12s 326us/step - loss: 0.0079\n",
      "Epoch 25/100\n",
      "35955/35955 [==============================] - 12s 329us/step - loss: 0.0079\n",
      "Epoch 26/100\n",
      "35955/35955 [==============================] - 12s 335us/step - loss: 0.0078\n",
      "Epoch 27/100\n",
      "35955/35955 [==============================] - 12s 331us/step - loss: 0.0078\n",
      "Epoch 28/100\n",
      "35955/35955 [==============================] - 12s 328us/step - loss: 0.0078\n",
      "Epoch 29/100\n",
      "35955/35955 [==============================] - 12s 335us/step - loss: 0.0077\n",
      "Epoch 30/100\n",
      "35955/35955 [==============================] - 12s 344us/step - loss: 0.0077\n",
      "Epoch 31/100\n",
      "35955/35955 [==============================] - 14s 400us/step - loss: 0.0077\n",
      "Epoch 32/100\n",
      "35955/35955 [==============================] - 9s 243us/step - loss: 0.0076\n",
      "Epoch 33/100\n",
      "35955/35955 [==============================] - 8s 226us/step - loss: 0.0076\n",
      "Epoch 34/100\n",
      "35955/35955 [==============================] - 8s 220us/step - loss: 0.0076\n",
      "Epoch 35/100\n",
      "35955/35955 [==============================] - 8s 223us/step - loss: 0.0076\n",
      "Epoch 36/100\n",
      "35955/35955 [==============================] - 8s 219us/step - loss: 0.0075\n",
      "Epoch 37/100\n",
      "35955/35955 [==============================] - 8s 225us/step - loss: 0.0075\n",
      "Epoch 38/100\n",
      "35955/35955 [==============================] - 8s 222us/step - loss: 0.0075\n",
      "Epoch 39/100\n",
      "35955/35955 [==============================] - 8s 221us/step - loss: 0.0075\n",
      "Epoch 40/100\n",
      "35955/35955 [==============================] - 8s 221us/step - loss: 0.0074\n",
      "Epoch 41/100\n",
      "35955/35955 [==============================] - 8s 221us/step - loss: 0.0074\n",
      "Epoch 42/100\n",
      "35955/35955 [==============================] - 8s 222us/step - loss: 0.0074\n",
      "Epoch 43/100\n",
      "35955/35955 [==============================] - 8s 219us/step - loss: 0.0074\n",
      "Epoch 44/100\n",
      "35955/35955 [==============================] - 8s 222us/step - loss: 0.0074\n",
      "Epoch 45/100\n",
      "35955/35955 [==============================] - 8s 223us/step - loss: 0.0074\n",
      "Epoch 46/100\n",
      "35955/35955 [==============================] - 8s 220us/step - loss: 0.0073\n",
      "Epoch 47/100\n",
      "35955/35955 [==============================] - 8s 222us/step - loss: 0.0073\n",
      "Epoch 48/100\n",
      "35955/35955 [==============================] - ETA: 0s - loss: 0.007 - 8s 224us/step - loss: 0.0073\n",
      "Epoch 49/100\n",
      "35955/35955 [==============================] - 8s 220us/step - loss: 0.0073\n",
      "Epoch 50/100\n",
      "35955/35955 [==============================] - 8s 221us/step - loss: 0.0073\n",
      "Epoch 51/100\n",
      "35955/35955 [==============================] - 8s 222us/step - loss: 0.0073\n",
      "Epoch 52/100\n",
      "35955/35955 [==============================] - 8s 223us/step - loss: 0.0073\n",
      "Epoch 53/100\n",
      "35955/35955 [==============================] - 8s 217us/step - loss: 0.0072\n",
      "Epoch 54/100\n",
      "35955/35955 [==============================] - 8s 219us/step - loss: 0.0072\n",
      "Epoch 55/100\n",
      "35955/35955 [==============================] - 8s 218us/step - loss: 0.0072\n",
      "Epoch 56/100\n",
      "35955/35955 [==============================] - 8s 217us/step - loss: 0.0072\n",
      "Epoch 57/100\n",
      "35955/35955 [==============================] - 8s 218us/step - loss: 0.0072\n",
      "Epoch 58/100\n",
      "35955/35955 [==============================] - 8s 216us/step - loss: 0.0072\n",
      "Epoch 59/100\n",
      "35955/35955 [==============================] - 8s 215us/step - loss: 0.0072\n",
      "Epoch 60/100\n",
      "35955/35955 [==============================] - 8s 221us/step - loss: 0.0072\n",
      "Epoch 61/100\n",
      "35955/35955 [==============================] - 8s 216us/step - loss: 0.0071\n",
      "Epoch 62/100\n",
      "35955/35955 [==============================] - 8s 217us/step - loss: 0.0071\n",
      "Epoch 63/100\n",
      "35955/35955 [==============================] - 8s 218us/step - loss: 0.0071\n",
      "Epoch 64/100\n",
      "35955/35955 [==============================] - 8s 216us/step - loss: 0.0071\n",
      "Epoch 65/100\n",
      "35955/35955 [==============================] - 8s 217us/step - loss: 0.0071\n",
      "Epoch 66/100\n",
      "35955/35955 [==============================] - 8s 216us/step - loss: 0.0071\n",
      "Epoch 67/100\n",
      "35955/35955 [==============================] - 8s 216us/step - loss: 0.0071\n",
      "Epoch 68/100\n",
      "35955/35955 [==============================] - 8s 222us/step - loss: 0.0071\n",
      "Epoch 69/100\n",
      "35955/35955 [==============================] - 8s 223us/step - loss: 0.0071\n",
      "Epoch 70/100\n",
      "35955/35955 [==============================] - 8s 222us/step - loss: 0.0070\n",
      "Epoch 71/100\n",
      "35955/35955 [==============================] - ETA: 0s - loss: 0.007 - 8s 218us/step - loss: 0.0070\n",
      "Epoch 72/100\n",
      "35955/35955 [==============================] - 8s 218us/step - loss: 0.0070\n",
      "Epoch 73/100\n",
      "35955/35955 [==============================] - 10s 278us/step - loss: 0.0070\n",
      "Epoch 74/100\n",
      "35955/35955 [==============================] - 9s 250us/step - loss: 0.0070\n",
      "Epoch 75/100\n",
      "35955/35955 [==============================] - 10s 274us/step - loss: 0.0070\n",
      "Epoch 76/100\n",
      "35955/35955 [==============================] - 10s 266us/step - loss: 0.0070\n",
      "Epoch 77/100\n",
      "35955/35955 [==============================] - 11s 312us/step - loss: 0.0070\n",
      "Epoch 78/100\n",
      "35955/35955 [==============================] - 11s 301us/step - loss: 0.0070\n",
      "Epoch 79/100\n",
      "35955/35955 [==============================] - 9s 260us/step - loss: 0.0070\n",
      "Epoch 80/100\n",
      "35955/35955 [==============================] - 10s 271us/step - loss: 0.0070\n",
      "Epoch 81/100\n",
      "35955/35955 [==============================] - 10s 289us/step - loss: 0.0069\n",
      "Epoch 82/100\n",
      "35955/35955 [==============================] - 10s 283us/step - loss: 0.0069\n",
      "Epoch 83/100\n",
      "35955/35955 [==============================] - 10s 271us/step - loss: 0.0069\n",
      "Epoch 84/100\n",
      "35955/35955 [==============================] - 9s 258us/step - loss: 0.0069\n",
      "Epoch 85/100\n",
      "35955/35955 [==============================] - 9s 249us/step - loss: 0.0069\n",
      "Epoch 86/100\n",
      "35955/35955 [==============================] - 9s 247us/step - loss: 0.0069\n",
      "Epoch 87/100\n",
      "35955/35955 [==============================] - 11s 301us/step - loss: 0.0069\n",
      "Epoch 88/100\n",
      "35955/35955 [==============================] - 10s 264us/step - loss: 0.0069\n",
      "Epoch 89/100\n",
      "35955/35955 [==============================] - 8s 219us/step - loss: 0.0069\n",
      "Epoch 90/100\n",
      "35955/35955 [==============================] - 8s 228us/step - loss: 0.0069\n",
      "Epoch 91/100\n",
      "35955/35955 [==============================] - 8s 226us/step - loss: 0.0069\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35955/35955 [==============================] - 8s 222us/step - loss: 0.0069\n",
      "Epoch 93/100\n",
      "35955/35955 [==============================] - 8s 218us/step - loss: 0.0069\n",
      "Epoch 94/100\n",
      "35955/35955 [==============================] - 8s 216us/step - loss: 0.0069\n",
      "Epoch 95/100\n",
      "35955/35955 [==============================] - 8s 218us/step - loss: 0.0069\n",
      "Epoch 96/100\n",
      "35955/35955 [==============================] - 8s 221us/step - loss: 0.0068\n",
      "Epoch 97/100\n",
      "35955/35955 [==============================] - 8s 218us/step - loss: 0.0068\n",
      "Epoch 98/100\n",
      "35955/35955 [==============================] - 8s 219us/step - loss: 0.0068\n",
      "Epoch 99/100\n",
      "35955/35955 [==============================] - 8s 216us/step - loss: 0.0068\n",
      "Epoch 100/100\n",
      "35955/35955 [==============================] - 8s 216us/step - loss: 0.0068\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit([targetArr , molregNoArr], latfeatureArr,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypred = model.predict([targetArr[:30,:],molregNoArr[:30,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm temp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### Load MVAE\n",
    "import numpy as np\n",
    "import json\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from mVAE.model import MoleculeVAE\n",
    "from mVAE.utils import encode_smiles, decode_latent_molecule, interpolate, get_unique_mols\n",
    "#import mVAE.mVAE\n",
    "# number of dimensions to represent the molecules\n",
    "# as the model was trained with this number, any operation made with the model must share the dimensions.\n",
    "latent_dim = 292\n",
    "\n",
    "# trained_model 0.99 validation accuracy\n",
    "# trained with 80% of ALL chembl molecules, validated on the other 20.\n",
    "trained_model = 'mVAE/chembl_23_model.h5'\n",
    "charset_file = 'charset.json'\n",
    "\n",
    "# load charset and model\n",
    "with open('mVAE/charset.json', 'r') as outfile:\n",
    "    charset = json.load(outfile)\n",
    "\n",
    "modelVae = MoleculeVAE()\n",
    "modelVae.load(charset, trained_model, latent_rep_size = latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssayDataSetForDeeplearning.csv\r\n",
      "Chembl23DataSetForFiltering_5andMore.csv\r\n",
      "CompoundFingerPrints_LatentFectors_MultiBinary.csv\r\n",
      "FeaturesAsMatrixv1.csv\r\n",
      "TargetFingerPrints_LatentFectors_MultiBinary.csv\r\n",
      "smilesCode.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of successful predictions 0\n"
     ]
    }
   ],
   "source": [
    "reconstructed_aspirin = decode_latent_molecule(ypred[12,:], modelVae, charset, 292)\n",
    "#original = Chem.MolFromSmiles(testSMILES)\n",
    "reconstructued = Chem.MolFromSmiles(reconstructed_aspirin)\n",
    "\n",
    "#Draw.MolsToGridImage([reconstructued])\n",
    "from rdkit import RDLogger\n",
    "# remove warnings and errors from notebook (lots of them due non valid molecule generation)\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "workingMols = list()\n",
    "for predMols in ypred:\n",
    "    decodedSmiles =  decode_latent_molecule(predMols, modelVae, charset, 292)\n",
    "    reconstructued = Chem.MolFromSmiles(decodedSmiles)\n",
    "    \n",
    "    if reconstructued:\n",
    "        print(decodedSmiles)\n",
    "        workingMols.append(reconstructued)\n",
    "        \n",
    "print(\"No of successful predictions %d\"%len(workingMols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10926732,  0.09486426,  0.14250977,  0.05274021, -0.0953891 ,\n",
       "        0.06582877,  0.12305044, -0.05070004, -0.24215151,  0.12526383], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred[0,0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
